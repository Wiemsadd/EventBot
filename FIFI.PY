# EventBot Pro - Version am√©lior√©e avec modularit√©, gestion d'erreurs et interface optimis√©e

# üîπ Imports
from langchain_ollama import ChatOllama
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.prompts import PromptTemplate
from langchain.chains import RetrievalQA
from langchain_core.documents import Document
from langchain_community.document_loaders import PyPDFLoader
import gradio as gr
import sqlite3
import os

# üîπ Configuration
EMBEDDING_MODEL = "sentence-transformers/all-MiniLM-L6-v2"
LLM_MODEL = "llama3.2"
DB_PATH = "./event_docs.db"
PDF_PATHS = [
    "pdfs/idees_themes.pdf",
    "pdfs/budget_mariage.pdf",
    "pdfs/logistique_conference.pdf",
    "pdfs/planning_evenement.pdf",
    "pdfs/to do list mariage.pdf"
]

# üîπ Initialisation LLM et embeddings
embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)
llm = ChatOllama(model=LLM_MODEL, temperature=0.2)

# üîπ Base de donn√©es SQLite
def get_db_connection():
    return sqlite3.connect(DB_PATH)

conn = get_db_connection()
cursor = conn.cursor()
cursor.execute("""
CREATE TABLE IF NOT EXISTS documents (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    title TEXT,
    content TEXT,
    type TEXT
)
""")
conn.commit()

# üîπ D√©tection du type d'√©v√©nement √† partir du nom du fichier
def detect_type_from_filename(filename):
    fname = filename.lower()
    if "mariage" in fname:
        return "MARIAGE"
    elif "logistique" in fname or "conference" in fname:
        return "SEMINAIRE"
    elif "salon" in fname:
        return "SALON"
    elif "theme" in fname or "idee" in fname or "creatif" in fname or "ambiance" in fname:
        return "CR√âATIVIT√â"
    elif "budget" in fname or "finance" in fname:
        return "BUDGET"
    elif "planning" in fname or "programme" in fname:
        return "PLANIFICATION"
    else:
        return "SEMINAIRE"

# üîπ Insertion des PDFs dans la base
def insert_pdfs():
    missing_files = []
    for pdf_path in PDF_PATHS:
        if not os.path.exists(pdf_path):
            missing_files.append(pdf_path)
            print(f"‚ö†Ô∏è Fichier manquant: {pdf_path}")
            continue
        try:
            loader = PyPDFLoader(pdf_path)
            docs = loader.load()
            full_text = "\n".join(doc.page_content for doc in docs)
            title = os.path.basename(pdf_path)
            doc_type = detect_type_from_filename(title)
            cursor.execute("SELECT COUNT(*) FROM documents WHERE title = ?", (title,))
            if cursor.fetchone()[0] == 0:
                cursor.execute("INSERT INTO documents (title, content, type) VALUES (?, ?, ?)",
                           (title, full_text, doc_type))
        except Exception as e:
            print(f"‚ùå Erreur lors du traitement de {pdf_path}: {str(e)}")
    
    conn.commit()
    if missing_files:
        print(f"‚ö†Ô∏è Fichiers manquants: {', '.join(missing_files)}")
        print("Veuillez vous assurer que tous les fichiers PDF sont pr√©sents dans le r√©pertoire.")

insert_pdfs()

# üîπ Chargement des documents depuis la base
def load_documents_from_db():
    cursor.execute("SELECT title, content, type FROM documents")
    rows = cursor.fetchall()
    return [Document(page_content=row[1], metadata={"title": row[0], "type": row[2]}) for row in rows]

# üîπ Prompts sp√©cialis√©s
prompt_map = {
    "BUDGET": PromptTemplate(
        input_variables=["context", "question"],
        template="""
Tu es eventbot, expert en gestion financi√®re d'√©v√©nements.
Fais une estimation claire et strat√©gique selon le contexte.

üìö CONTEXTE:
{context}

‚ùì QUESTION:
{question}

üí∞ BUDGET:
"""
    ),
    "PLANIFICATION": PromptTemplate(
        input_variables=["context", "question"],
        template="""
Tu es eventbot, expert en planification d√©taill√©e d'√©v√©nements.

üìö CONTEXTE:
{context}

‚ùì QUESTION:
{question}

üìÖ PLAN D'ACTION:
"""
    ),
    "SEMINAIRE": PromptTemplate(
        input_variables=["context", "question"],
        template="""
Tu es eventbot , sp√©cialiste de l'organisation de s√©minaires professionnels.
Base-toi sur le contexte fourni pour r√©pondre √† la question suivante.

üìö CONTEXTE:
{context}

‚ùì QUESTION:
{question}

‚úÖ R√âPONSE:
"""
    ),
    "MARIAGE": PromptTemplate(
        input_variables=["context", "question"],
        template="""
Tu es eventbot, un expert de l'organisation de mariages inoubliables.

üìö CONTEXTE:
{context}

‚ùì QUESTION:
{question}

üíñ CONSEIL:
"""
    ),
    "SALON": PromptTemplate(
        input_variables=["context", "question"],
        template="""
Tu es eventbot, expert des salons et expositions.

üìö CONTEXTE:
{context}

‚ùì QUESTION:
{question}

üè¢ STRAT√âGIE:
"""
    ),
    "CR√âATIVIT√â": PromptTemplate(
        input_variables=["context", "question"],
        template="""
Tu es eventbot, un expert en id√©es th√©matiques et concepts d'ambiance.

üìö CONTEXTE:
{context}

‚ùì QUESTION:
{question}

‚ú® ID√âES:
"""
    )
}

# üîπ Fonction pour cr√©er le retriever √† partir des documents
def create_retriever():
    all_docs = load_documents_from_db()
    splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=150)
    if all_docs:
        chunks = splitter.split_documents(all_docs)
        vectorstore = FAISS.from_documents(chunks, embeddings)
        return vectorstore.as_retriever(search_kwargs={"k": 3})
    else:
        dummy_doc = Document(page_content="Bienvenue sur EventBot Pro. Aucun document n'est encore disponible.",
                             metadata={"title": "Bienvenue", "type": "SEMINAIRE"})
        chunks = splitter.split_documents([dummy_doc])
        vectorstore = FAISS.from_documents(chunks, embeddings)
        return vectorstore.as_retriever(search_kwargs={"k": 3})

# üîπ Initialisation du retriever et de la cha√Æne QA
retriever = create_retriever()
default_prompt = prompt_map["SEMINAIRE"]
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=retriever,
    chain_type="stuff",
    chain_type_kwargs={"prompt": default_prompt}
)

# üîπ Classification simple du type d'√©v√©nement
def detect_event_type(question):
    q = question.lower()
    if any(word in q for word in ["mariage", "noces", "fian√ßailles"]):
        return "MARIAGE"
    elif any(word in q for word in ["salon", "exposition", "stand"]):
        return "SALON"
    elif any(word in q for word in ["ambiance", "th√®me", "d√©coration", "id√©es", "cr√©atif"]):
        return "CR√âATIVIT√â"
    elif any(word in q for word in ["budget", "financement", "co√ªt", "prix"]):
        return "BUDGET"
    elif any(word in q for word in ["planning", "planification", "√©tapes", "programme"]):
        return "PLANIFICATION"
    else:
        return "SEMINAIRE"

# üîπ Interface Gradio
with gr.Blocks(theme=gr.themes.Soft()) as interface:
    gr.Markdown("""
    # ü§ñ EventBot Pro - Assistant intelligent
    Posez votre question : th√®mes, organisation, planning, mariage ou salon.
    """)

    chatbot = gr.Chatbot(label="üß† Discussion", height=500, type="messages")
    question_input = gr.Textbox(label="Votre question", placeholder="Ex: Des id√©es de th√®mes originaux pour un mariage en √©t√©?", lines=2)
    status_box = gr.Textbox(label="√âtat", interactive=True)
    ask_btn = gr.Button("Envoyer")
    clear_btn = gr.Button("Effacer")

    def ask_question(question, chat_display):
        if not question.strip():
            return chat_display, "‚ùó Entrez une question."

        event_type = detect_event_type(question)
        qa_chain.combine_documents_chain.llm_chain.prompt = prompt_map.get(event_type, default_prompt)

        try:
            result = qa_chain.invoke({"query": question, "question": question})
            answer = result.get("result", "Je n'ai pas de r√©ponse.")
        except Exception as e:
            print(f"Erreur : {e}")
            answer = "Erreur lors de la g√©n√©ration."

        chat_display.append({"role": "user", "content": question})
        chat_display.append({"role": "assistant", "content": answer})
        return chat_display, ""

    def clear_chat():
        return [], ""

    ask_btn.click(ask_question, inputs=[question_input, chatbot], outputs=[chatbot, status_box])
    clear_btn.click(clear_chat, outputs=[chatbot, status_box])
    question_input.submit(ask_question, inputs=[question_input, chatbot], outputs=[chatbot, status_box])

# üîπ Lancement de l'interface
if __name__ == "__main__":
    try:
        interface.launch(share=True)
    finally:
        conn.close()  # Ensure database connection is closed